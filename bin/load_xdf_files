import argparse
import numpy as np
import mne
from scipy.signal import butter, filtfilt, iirnotch, detrend
import pyxdf  # For loading .xdf files
import os
import re

def load_xdf_file(filepath):
    """Load the XDF file using pyxdf."""
    streams, header = pyxdf.load_xdf(filepath)
    print(f"Loaded XDF file: {filepath}")
    print(f"Number of streams: {len(streams)}")
    
    # Print stream details to help debug
    for idx, stream in enumerate(streams):
        stream_name = stream['info']['name'][0]
        stream_srate = stream['info']['effective_srate']
        print(f"Stream {idx + 1}: {stream_name}")
        print(f"Sampling rate: {stream_srate}")

        if 'desc' in stream['info']:
            desc = stream['info']['desc']
            if desc and isinstance(desc, list) and len(desc) > 0:
                if isinstance(desc[0], dict) and 'channels' in desc[0]:
                    channels_info = desc[0]['channels']
                    if channels_info and 'channel' in channels_info[0]:
                        num_channels = len(channels_info[0]['channel'])
                        print(f"Number of channels: {num_channels}")
                    else:
                        print(f"Stream {stream_name} has no 'channel' field in channels information.")
                else:
                    print(f"Stream {stream_name} has no 'channels' key or the structure is unexpected.")
            else:
                print(f"Stream {stream_name} has an empty or invalid 'desc'.")
        else:
            print(f"Stream {stream_name} has no 'desc' information.")
    
    return streams, header

def find_xdf_files(base_dir):
    """Find all .xdf files within the given directory and its subdirectories."""
    file_paths = []
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith(".xdf"):
                file_paths.append(os.path.join(root, file))
    return file_paths

def process_all_xdf_files(base_dir, base_save_dir):
    """Process all .xdf files in the LEFT and RIGHT directories by applying perform_ICA."""
    left_dir = os.path.join(base_dir, 'LEFT')
    right_dir = os.path.join(base_dir, 'RIGHT')

    left_files = find_xdf_files(left_dir)
    right_files = find_xdf_files(right_dir)

    print(f"Found {len(left_files)} files in LEFT directory.")
    print(f"Found {len(right_files)} files in RIGHT directory.")

    for left_file in left_files:
        print(f"Processing {left_file}...")
        streams_L, header_L = load_xdf_file(left_file)
        try:
            EEG_DATA_L, ICA_L, timestamps_L, relevant_time_series_L, event_timestamps_L = perform_ICA(streams_L, 1, left_file, base_save_dir)
        except Exception as e:
            print(f"Error processing {left_file}: {e}")

    for right_file in right_files:
        print(f"Processing {right_file}...")
        streams_R, header_R = load_xdf_file(right_file)
        try:
            EEG_DATA_R, ICA_R, timestamps_R, relevant_time_series_R, event_timestamps_R = perform_ICA(streams_R, 2, right_file, base_save_dir)
        except Exception as e:
            print(f"Error processing {right_file}: {e}")

def perform_ICA(streams, side_identifier, xdf_filename, base_save_dir, trim_samples=(0, 0)):
    """
    Perform ICA on EEG data and save the ICA solution and filtered raw EEG data.
    """
    print(f"Length of the streams list: {len(streams)}")

    data = None
    sampling_rate = None
    timestamps = None
    event_timestamps = []

    first_stream_data = np.array(streams[0]['time_series'])
    second_stream_data = np.array(streams[1]['time_series']) if len(streams) > 1 else None

    for idx, stream in enumerate(streams):
        stream_data = np.array(stream['time_series'])
        if stream_data.shape[1] == 10 and streams[idx]['info']['effective_srate'] > 0:
            data = stream_data
            sampling_rate = streams[idx]['info']['effective_srate']
            timestamps = np.array(stream['time_stamps'])
            print(f"Using stream {idx + 1} with shape: {data.shape}")
            break
    else:
        raise ValueError("No valid EEG data found in the streams.")

    for idx, stream in enumerate(streams):
        stream_data = np.array(stream['time_series'])
        if stream_data.shape[1] == 30 and stream_data.shape[0] == 1:
            event_timestamps.extend(stream['time_stamps'])
            print(f"Found event data in stream {idx + 1} with timestamps: {stream['time_stamps']}")

    if not isinstance(data, np.ndarray) or not np.issubdtype(data.dtype, np.number):
        raise ValueError("No valid numeric data found in any of the streams.")

    if trim_samples[0] > 0 or trim_samples[1] > 0:
        trim_start = min(trim_samples[0], data.shape[0])
        trim_end = min(trim_samples[1], data.shape[0])
        data = data[trim_start:data.shape[0] - trim_end]
        if timestamps is not None:
            timestamps = timestamps[trim_start:len(timestamps) - trim_end]

    ch_names = ['F3', 'Fz', 'F4', 'C3', 'Cz', 'C4', 'P3', 'Pz', 'P4', 'GND']
    info = mne.create_info(ch_names=ch_names, sfreq=sampling_rate, ch_types='eeg')
    raw = mne.io.RawArray(data.T, info)

    montage = mne.channels.make_dig_montage({
        'F3': (-39, 0.33333, 0), 
        'Fz': (0, 0.25556, 0),
        'F4': (39, 0.33333, 0),
        'C3': (-90, 0.25556, 0),
        'Cz': (0, 0, 0),
        'C4': (90, 0.25556, 0),
        'P3': (-141, 0.33333, 0),
        'Pz': (180, 0.25556, 0),
        'P4': (141, 0.33333, 0),
        'GND': (0, -0.1, 0)
    })
    raw.set_montage(montage)

    notch_freq = 50
    filtered_raw = raw.copy().filter(l_freq=1.0, h_freq=None)
    filtered_raw.notch_filter(freqs=[notch_freq], method='iir')

    ica = mne.preprocessing.ICA(n_components=10, random_state=42, max_iter='auto')
    ica.fit(filtered_raw)
    filtered_raw = ica.apply(filtered_raw)

    subject_session = re.findall(r'ses-S\d+', xdf_filename)
    if len(subject_session) > 0:
        subject_session = subject_session[0]
        subject_id = subject_session.split('-')[1]

        # Ensure the subject_id is formatted with leading zeros (e.g., '001' instead of '1')
        subject_id = subject_id.zfill(3)  # To ensure we get '001', '002', ..., '010'

        # Determine the directory based on side identifier
        side_folder = 'L' if side_identifier == 1 else 'R'
        
        # Create the subject folder (e.g., 'S001', 'S002') inside the side folder
        subject_folder = f"{subject_id}"
        
        # Create subject folder inside the side folder if it doesn't exist
        output_dir = os.path.join(base_save_dir, side_folder, subject_folder)
        os.makedirs(output_dir, exist_ok=True)

        # Define filename prefix based on side identifier
        if side_identifier == 1:
            filename_prefix = f"sub-{subject_id}_L_eeg_ica"
        else:
            filename_prefix = f"sub-{subject_id}_R_eeg_raw"


        # Create the full paths for saving the raw and ICA files
        save_path_raw = os.path.join(output_dir, f"{filename_prefix}_raw.fif")
        save_path_ica = os.path.join(output_dir, f"{filename_prefix}_ica.fif")

        # Save files if they don't already exist
        if not os.path.exists(save_path_raw):
            filtered_raw.save(save_path_raw, overwrite=True)
            print(f"Filtered raw data saved to: {save_path_raw}")
        else:
            print(f"File {save_path_raw} already exists. Skipping save.")

        if not os.path.exists(save_path_ica):
            ica.save(save_path_ica, overwrite=True)
            print(f"ICA solution saved to: {save_path_ica}")
        else:
            print(f"File {save_path_ica} already exists. Skipping save.")

    return filtered_raw, ica, timestamps, data, event_timestamps

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="XDF EEG File Processor")
    parser.add_argument('-b','--base_dir', required=True, help='Base directory containing LEFT and RIGHT folders with .xdf files.')
    parser.add_argument('-o','--output_dir', required=True, help='Output directory to save processed files.')
    args = parser.parse_args()

    process_all_xdf_files(args.base_dir, args.output_dir)
