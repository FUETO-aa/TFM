import argparse
import numpy as np
import mne
from scipy.signal import butter, filtfilt, iirnotch, detrend
import pyxdf
import os
import re
import json

def load_xdf_file(filepath):
    """Load the XDF file using pyxdf and log details about each stream."""
    streams, header = pyxdf.load_xdf(filepath)
    print(f"Loaded XDF file: {filepath}")
    print(f"Number of streams: {len(streams)}")
    
    # Debug: Stream details
    for idx, stream in enumerate(streams):
        stream_name = stream['info']['name'][0]
        stream_srate = stream['info']['effective_srate']
        stream_shape = np.array(stream['time_series']).shape
        print(f"Stream {idx + 1} - Name: {stream_name}")
        print(f"Sampling rate: {stream_srate}")
        print(f"Time series shape: {stream_shape}")
        print(f"First 10 timestamps: {stream['time_stamps'][:10]}")
        print(f"First 10 data points: {np.array(stream['time_series'])[:10]}")
    
    return streams, header

def find_xdf_files(base_dir):
    """Find all .xdf files within the given directory and its subdirectories."""
    file_paths = []
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith(".xdf"):
                file_paths.append(os.path.join(root, file))
    return file_paths

def process_all_xdf_files(base_dir, base_save_dir):
    """Process all .xdf files in the LEFT and RIGHT directories."""
    left_dir = os.path.join(base_dir, 'LEFT')
    right_dir = os.path.join(base_dir, 'RIGHT')

    left_files = find_xdf_files(left_dir)
    right_files = find_xdf_files(right_dir)

    print(f"Found {len(left_files)} files in LEFT directory.")
    print(f"Found {len(right_files)} files in RIGHT directory.")

    for left_file in left_files:
        print(f"Processing {left_file}...")
        streams_L, header_L = load_xdf_file(left_file)
        try:
            EEG_DATA_L, ICA_L, timestamps_L, relevant_time_series_L, event_timestamps_L = perform_ICA(
                streams_L, 'L', left_file, base_save_dir
            )
        except Exception as e:
            print(f"Error processing {left_file}: {e}")

    for right_file in right_files:
        print(f"Processing {right_file}...")
        streams_R, header_R = load_xdf_file(right_file)
        try:
            EEG_DATA_R, ICA_R, timestamps_R, relevant_time_series_R, event_timestamps_R = perform_ICA(
                streams_R, 'R', right_file, base_save_dir
            )
        except Exception as e:
            print(f"Error processing {right_file}: {e}")

def perform_ICA(streams, side_label, xdf_filename, base_save_dir, trim_samples=(0, 0)):
    """
    Perform ICA on EEG data, save the ICA solution, filtered raw EEG data, and ICA-applied data.
    Store specific data segments (1 seconds after events) and event timestamps in a JSON file.
    """
    data, sampling_rate, timestamps, event_timestamps = None, None, None, []

    # Extract EEG data (assumes it has 10 channels)
    for idx, stream in enumerate(streams):
        stream_data = np.array(stream['time_series'])
        if stream_data.shape[1] == 10 and stream['info']['effective_srate'] > 0:
            data = stream_data
            sampling_rate = stream['info']['effective_srate']
            timestamps = np.array(stream['time_stamps'])
            print(f"Using EEG data from stream {idx + 1} with shape: {data.shape}")
            break
    else:
        raise ValueError("No valid EEG data found in the streams.")

    # Identify event timestamps (assuming single-channel stream indicates events)
    for idx, stream in enumerate(streams):
        stream_data = np.array(stream['time_series'])
        if stream_data.shape[1] == 1:  # Check for single-channel stream (likely event markers)
            print(f"Checking stream {idx + 1} for event markers...")
            for ts, value in zip(stream['time_stamps'], stream_data[:, 0]):
                if value != 0:  # Assuming non-zero values are event markers
                    event_timestamps.append(ts)
                    print(f"Event found at {ts} with marker value {value}")

    # Prepare MNE Raw object
    ch_names = ['F3', 'Fz', 'F4', 'C3', 'Cz', 'C4', 'P3', 'Pz', 'P4', 'GND']
    info = mne.create_info(ch_names=ch_names, sfreq=sampling_rate, ch_types='eeg')
    raw = mne.io.RawArray(data.T, info)

    # Set montage for electrode layout
    montage = mne.channels.make_dig_montage({
        'F3': (-39, 0.33333, 0), 'Fz': (0, 0.25556, 0),
        'F4': (39, 0.33333, 0), 'C3': (-90, 0.25556, 0),
        'Cz': (0, 0, 0), 'C4': (90, 0.25556, 0),
        'P3': (-141, 0.33333, 0), 'Pz': (180, 0.25556, 0),
        'P4': (141, 0.33333, 0), 'GND': (0, -0.1, 0)
    })
    raw.set_montage(montage)

    # Apply filtering and ICA
    filtered_raw = raw.copy().filter(l_freq=1.0, h_freq=None)
    filtered_raw.notch_filter(freqs=[50], method='iir')

    ica = mne.preprocessing.ICA(n_components=10, random_state=42, max_iter='auto')
    ica.fit(filtered_raw)
    filtered_ica_raw = filtered_raw.copy()
    ica.apply(filtered_ica_raw)

    # Output paths
    subject_id = re.findall(r'ses-S\d+', xdf_filename)[0].split('-')[1].zfill(3)
    output_dir = os.path.join(base_save_dir, side_label, f"{subject_id}")
    os.makedirs(output_dir, exist_ok=True)

    # Save raw, ICA, and filtered ICA data
    raw.save(os.path.join(output_dir, f"sub-{subject_id}_{side_label}_eeg_raw.fif"), overwrite=True)
    ica.save(os.path.join(output_dir, f"sub-{subject_id}_{side_label}_eeg_ica.fif"), overwrite=True)
    filtered_ica_raw.save(os.path.join(output_dir, f"sub-{subject_id}_{side_label}_eeg_ica_filtered_raw.fif"), overwrite=True)

    # Event data JSON with side label and 2-second segments after each event
    json_data = {
        "side": side_label,
        "event_timestamps": [float(ts) for ts in event_timestamps],
        "data_segments": []
    }

    # Extract 2-second segments after each event timestamp
    segment_duration_samples = int(1 * sampling_rate)  # Duration of 2 seconds in samples

    # Retrieve the data from the filtered ICA raw object
    filtered_ica_data = filtered_ica_raw.get_data()

    for event_time in event_timestamps:
        # Find the index corresponding to the event_time
        event_index = np.searchsorted(timestamps, event_time)
        # Calculate the end index for a 2-second segment
        end_index = min(event_index + segment_duration_samples, filtered_ica_data.shape[1])

        # Extract the segment of the data for this event
        ica_segment = filtered_ica_data[:, event_index:end_index]

        # Store the event time and the corresponding segment
        json_data["data_segments"].append({
            "event_time": float(event_time),
            "ica_segment": ica_segment.tolist()  # Convert to list for JSON serialization
        })

    json_path = os.path.join(output_dir, f"sub-{subject_id}_{side_label}_event_data.json")
    with open(json_path, "w") as json_file:
        json.dump(json_data, json_file, indent=4)
        print(f"Event data and segments saved to: {json_path}")

    # Instead of JSON, store in a NumPy .npz file
    npz_data_path = os.path.join(output_dir, f"sub-{subject_id}_{side_label}_event_data.npz")
    np.savez(npz_data_path, event_timestamps=np.array(event_timestamps), data_segments=np.array(json_data["data_segments"]))
    print(f"Event data and segments saved to: {npz_data_path}")


    return filtered_ica_raw, ica, timestamps, data, event_timestamps


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="XDF EEG File Processor")
    parser.add_argument('-b','--base_dir', required=True, help='Base directory containing LEFT and RIGHT folders with .xdf files.')
    parser.add_argument('-o','--output_dir', required=True, help='Output directory to save processed files.')
    args = parser.parse_args()

    process_all_xdf_files(args.base_dir, args.output_dir)
